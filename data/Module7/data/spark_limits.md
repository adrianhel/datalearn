## 7.14.1 Ограничения Spark

### [Назад в Модуль 7 ⤶](/data/Module7/readme.md)

1. Ограничения работы с памятью  
   - **Обработка в памяти:** Spark преимущественно использует оперативную память для хранения промежуточных данных, 
   что обеспечивает высокую производительность. Однако это ограничивает объём обрабатываемых данных объёмом доступной 
   памяти кластера.  
   - **Out of Memory:** При нехватке памяти возможны ошибки `OutOfMemoryError` и сбои выполнения задач. Эффективное 
   управление памятью (memory management) критично для стабильной работы.  
   - **Garbage Collection:** Частая сборка мусора (GC) может привести к падению производительности. Необходима 
   оптимизация структур данных и партиционирования.  

2. Ограничения по масштабируемости  
   - **Сетевые задержки:** При увеличении числа узлов на кластере возрастает нагрузка на сеть, что может привести 
   к задержкам передачи данных и деградации производительности.  
   - **Shuffle и перекидка данных:** Операции, требующие обмена данными между разделами (shuffle), 
   например `groupByKey`, `reduceByKey`, `join`, существенно влияют на масштабируемость и могут стать узким местом.  
   - **Ограничения драйвера:** Драйвер Spark должен управлять всеми задачами, что накладывает ограничения на общий 
   объём задач и размер DAG (Directed Acyclic Graph).  
   
3. Ограничения модели обработки данных  
   - **RDD и неизменяемость:** Основная абстракция Spark — RDD (Resilient Distributed Dataset) — является неизменяемой 
   структурой данных. Это повышает устойчивость, но усложняет реализацию некоторых алгоритмов, требующих изменяемых 
   структур.  
   - **Ограничения трансформаций:** Некоторые высокоуровневые операции (например, `groupByKey`) крайне неэффективны 
   при работе с большими объёмами данных из-за необходимости shuffle.  
   - **Нет поддержки транзакций:** Spark не поддерживает ACID-транзакции и не гарантирует согласованность данных 
   между различными задачами.  

4. Ограничения хранения данных  
   - **Отсутствие собственного хранилища:** Spark не является системой хранения данных. Для хранения исходных и 
   результирующих данных используются внешние системы (HDFS, S3, базы данных и др.), что увеличивает задержки 
   на ввод-вывод.  
   - **Зависимость от формата данных:** Эффективность обработки напрямую зависит от формата хранения данных 
   (Parquet, Avro, CSV и др.). Неоптимальные форматы могут существенно снизить производительность.  

5. Ограничения потоковой обработки  
   - **Микро-пакетная обработка:** Spark Streaming использует подход микро-батчей, что ограничивает минимально 
   достижимую задержку обработки (latency) и не подходит для задач с жёсткими real-time требованиями.  
   - **Сложность обработки событий:** Нет встроенной поддержки сложных событийных паттернов 
   (CEP — Complex Event Processing), как в специализированных системах потоковой обработки.  

6. Ограничения по интеграции и совместимости  
   - **Языковые ограничения:** Несмотря на поддержку Scala, Java, Python и R, отдельные API (например, MLlib) 
   развиты неравномерно — многие функции доступны только в Scala или Python.  
   - **Совместимость библиотек:** Некоторые сторонние библиотеки могут быть несовместимы с последними версиями Spark, 
   что требует дополнительной проверки и тестирования.  

7. Ограничения безопасности  
   - **Ограниченная поддержка аутентификации и авторизации:** По умолчанию Spark не обеспечивает строгой модели 
   безопасности, и требуется интеграция с внешними инструментами (Kerberos, SSL, Ranger) для усиления контроля доступа.  
   - **Обработка чувствительных данных:** Не рекомендуется использовать Spark для обработки критичных данных без 
   дополнительных мер безопасности.  

8. Ограничения по отказоустойчивости и надежности  
   - **Восстановление после сбоев:** Spark восстанавливает вычисления с помощью lineage (цепочки преобразований RDD), 
   однако при больших DAG восстановление может быть ресурсоёмким и длительным.  
   - **Single Point of Failure:** Драйвер Spark является критической точкой отказа. При сбое драйвера выполнение 
   задания полностью прекращается.  

9. Ограничения по производительности  
   - **Зависимость от конфигурации:** Производительность Spark во многом определяется грамотной настройкой параметров 
   (число executors, cores, размер памяти, параметры shuffle и др.).  
   - **Влияние сложных вычислений:** Операции с высокой вычислительной сложностью или большим объёмом данных могут 
   привести к неэффективному использованию ресурсов.  
   - **Проблемы со skew (перекосом) данных:** Неравномерное распределение данных между разделами может привести к 
   неравномерной загрузке executors и увеличению времени выполнения задач.  

10. Ограничения при работе с MLlib и графовыми задачами
    - **MLlib:** Обработка больших моделей и сложных алгоритмов машинного обучения ограничивается объёмом доступной 
    памяти. Не все современные алгоритмы реализованы или оптимизированы для распределённых вычислений.  
    - **GraphX:** Модуль для работы с графами не масштабируется на экстремально большие графы, а также не поддерживает 
    динамические графы.  

## 7.14.2 Примеры кода, иллюстрирующие ограничения
### Проблема `shuffle` при `groupByKey`

```scala
val rdd = sc.parallelize(Seq(("a", 1), ("b", 2), ("a", 3), ("b", 4)))
val grouped = rdd.groupByKey()
grouped.collect()
// groupByKey вызывает полный shuffle всех данных с одинаковым ключом на один executor
```

### Ошибка `OutOfMemoryError` при большом количестве данных

```scala
val largeRdd = sc.parallelize(1 to 100000000)
largeRdd.map(_ * 2).collect()
// collect собирает все данные на драйвер, что приводит к OutOfMemoryError
```

