## 7.14.1 Ограничения Spark

### [Назад в Модуль 7 ⤶](/data/Module7/readme.md)

1. Ограничения работы с памятью  
   - **Обработка в памяти:** Spark преимущественно использует оперативную память для хранения промежуточных данных, 
   что обеспечивает высокую производительность. Однако это ограничивает объём обрабатываемых данных объёмом доступной 
   памяти кластера.  
   - **Out of Memory:** При нехватке памяти возможны ошибки `OutOfMemoryError` и сбои выполнения задач. Эффективное 
   управление памятью (memory management) критично для стабильной работы.  
   - **Garbage Collection:** Частая сборка мусора (GC) может привести к падению производительности. Необходима 
   оптимизация структур данных и партиционирования.  

2. Ограничения по масштабируемости  
   - **Сетевые задержки:** При увеличении числа узлов на кластере возрастает нагрузка на сеть, что может привести 
   к задержкам передачи данных и деградации производительности.  
   - **Shuffle и перекидка данных:** Операции, требующие обмена данными между разделами (shuffle), 
   например `groupByKey`, `reduceByKey`, `join`, существенно влияют на масштабируемость и могут стать узким местом.  
   - **Ограничения драйвера:** Драйвер Spark должен управлять всеми задачами, что накладывает ограничения на общий 
   объём задач и размер DAG (Directed Acyclic Graph).  

