## 7.14.1 Ограничения Spark

### [Назад в Модуль 7 ⤶](/data/Module7/readme.md)

1. Ограничения работы с памятью  
   - **Обработка в памяти:** Spark преимущественно использует оперативную память для хранения промежуточных данных, 
   что обеспечивает высокую производительность. Однако это ограничивает объём обрабатываемых данных объёмом доступной 
   памяти кластера.  
   - **Out of Memory:** При нехватке памяти возможны ошибки `OutOfMemoryError` и сбои выполнения задач. Эффективное 
   управление памятью (memory management) критично для стабильной работы.  
   - **Garbage Collection:** Частая сборка мусора (GC) может привести к падению производительности. Необходима 
   оптимизация структур данных и партиционирования.  

2. Ограничения по масштабируемости  
   - **Сетевые задержки:** При увеличении числа узлов на кластере возрастает нагрузка на сеть, что может привести 
   к задержкам передачи данных и деградации производительности.  
   - **Shuffle и перекидка данных:** Операции, требующие обмена данными между разделами (shuffle), 
   например `groupByKey`, `reduceByKey`, `join`, существенно влияют на масштабируемость и могут стать узким местом.  
   - **Ограничения драйвера:** Драйвер Spark должен управлять всеми задачами, что накладывает ограничения на общий 
   объём задач и размер DAG (Directed Acyclic Graph).  
   
3. Ограничения модели обработки данных  
   - **RDD и неизменяемость:** Основная абстракция Spark — RDD (Resilient Distributed Dataset) — является неизменяемой 
   структурой данных. Это повышает устойчивость, но усложняет реализацию некоторых алгоритмов, требующих изменяемых 
   структур.  
   - **Ограничения трансформаций:** Некоторые высокоуровневые операции (например, `groupByKey`) крайне неэффективны 
   при работе с большими объёмами данных из-за необходимости shuffle.  
   - **Нет поддержки транзакций:** Spark не поддерживает ACID-транзакции и не гарантирует согласованность данных 
   между различными задачами.  

4. Ограничения хранения данных  
   - **Отсутствие собственного хранилища:** Spark не является системой хранения данных. Для хранения исходных и 
   результирующих данных используются внешние системы (HDFS, S3, базы данных и др.), что увеличивает задержки 
   на ввод-вывод.  
   - **Зависимость от формата данных:** Эффективность обработки напрямую зависит от формата хранения данных 
   (Parquet, Avro, CSV и др.). Неоптимальные форматы могут существенно снизить производительность.  

