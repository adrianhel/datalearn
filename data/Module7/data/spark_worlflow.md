## 7.5.1 Workflow приложения Spark

### [Назад в Модуль 7 ⤶](/data/Module7/readme.md)

### Запуск автономного приложения и инициализация SparkContext

```python
from pyspark.sql import SparkSession

# Создание SparkSession
spark = SparkSession.builder.appName("Spark Workflow Example").getOrCreate()

# Получение SparkContext
sc = spark.sparkContext
```
                  
- Приложение, написанное на Python, Scala, Java или R, запускается автономно.  
- В этом приложении создается объект SparkSession (который включает SparkContext), инициализирующий необходимые 
компоненты для работы Spark.  
- Только при наличии SparkContext приложение называется драйвером (Driver).  

### Запрос ресурсов у менеджера кластеров
- Драйвер запрашивает у кластерного менеджера (например, YARN, Mesos, Kubernetes или Spark Standalone) ресурсы для 
выполнения задачи.  
- Драйвер сообщает кластерному менеджеру, сколько ресурсов ему требуется (например, количество исполнителей, объем 
памяти и процессорные ядра).  

```python
spark-submit \
  --master yarn \
  --deploy-mode cluster \
  --num-executors 10 \
  --executor-memory 4g \
  --executor-cores 2 \
  path/to/your_script.py
```
                  
### Запуск исполнителей менеджером кластеров

Кластерный менеджер распределяет ресурсы и запускает процессы исполнителей (executors) на рабочих узлах (worker nodes).
Каждый исполнитель запускает отдельный процесс, который будет выполнять задачи, переданные драйвером.
Запуск кода Spark драйвером

Драйвер начинает выполнение кода Spark, который включает чтение данных, выполнение преобразований (transformations) и действий (actions).
Драйвер разделяет задачи на этапы (stages) и назначает их исполнителям.
# Чтение данных
df = spark.read.csv("path/to/input.csv", header=True, inferSchema=True)

# Выполнение преобразований
df_filtered = df.filter(df["age"] > 30)
df_grouped = df_filtered.groupBy("city").count()

                  
Выполнение заданий исполнителями и отправка результатов драйверу

Исполнители получают задания от драйвера и начинают их выполнение.
Каждый исполнитель выполняет часть работы, такой как вычисления на данных и возвращает результаты драйверу.
# Действие, инициирующее выполнение заданий
result = df_grouped.collect()

                  
Остановка SparkContext и освобождение ресурсов

После завершения выполнения всех задач, драйвер останавливает SparkContext.
Исполнители закрываются и освобождают выделенные им ресурсы, возвращая их обратно в кластер.
# Остановка SparkSession и SparkContext
spark.stop()