## 7.11.1 Spark MLlib: машинное обучение

### [Назад в Модуль 7 ⤶](/data/Module7/readme.md)

**Машинное обучение (Machine Learning, ML)** — область искусственного интеллекта, занимающаяся разработкой алгоритмов 
и моделей, способных выявлять закономерности в данных и делать прогнозы или принимать решения без явного 
программирования. Ключевыми этапами процесса машинного обучения являются сбор и подготовка данных, выбор модели, 
обучение (training), валидация, тестирование и внедрение модели.  

**DataFrame API:** основной API для работы с MLlib, основанный на концепции таблиц с именованными столбцами.  

**ML Pipeline:** механизм построения последовательностей этапов обработки данных и обучения моделей, состоящий из 
трансформеров (transformers) и оценщиков (estimators).  

**Трансформеры (Transformers):** объекты, преобразующие DataFrame (например, StandardScaler, PCA, модель классификации).  

**Оценщики (Estimators):** объекты, которые могут быть обучены на данных и превращаются в трансформеры (например, 
LogisticRegression, DecisionTreeClassifier).  

**Параметры (Params):** механизм настройки поведения моделей и трансформеров через ключ-значение.  

**Модели (Models):** обученные экземпляры оценщиков, используемые для предсказаний.  

## 7.11.2 Типы задач машинного обучения
1. **Обучение с учителем (Supervised Learning):** используется, когда имеются размеченные данные (каждому объекту 
сопоставлена метка или значение целевой переменной).  
2. **Обучение без учителя (Unsupervised Learning):** задачи группировки данных или выявления структуры в неразмеченных 
данных.  
3. **Обучение с подкреплением (Reinforcement Learning):** в MLlib не реализовано.  

## 7.11.3 Основные алгоритмы и методы MLlib
### Классификация
**Классификация** — задача отнесения объектов к одному из заранее известных классов.  
  
- **Логистическая регрессия (Logistic Regression):** применяется для бинарной и многоклассовой классификации.  
- **Деревья решений (Decision Trees):** алгоритм построения дерева, где узлы — проверки признаков, листья — классы.  
- **Случайный лес (Random Forest):** ансамбль деревьев решений для повышения точности и устойчивости.  
- **Градиентный бустинг над деревьями (GBTClassifier):** ансамбль деревьев с последовательным обучением.  
- **Линейные методы (Linear SVM, Naive Bayes):** линейные классификаторы для различных задач.  

#### Пример кода: Логистическая регрессия

```python
from pyspark.ml.classification import LogisticRegression

lr = LogisticRegression(featuresCol="features", labelCol="label")
model = lr.fit(training_data)
predictions = model.transform(test_data)
```

                  
### Регрессия
**Регрессия** — предсказание числового значения целевой переменной.  
  
- **Линейная регрессия (Linear Regression):** базовый метод для регрессионных задач.  
- **Дерево решений для регрессии (DecisionTreeRegressor):** построение дерева для предсказания числовых значений.  
- **Случайный лес для регрессии (RandomForestRegressor):** ансамбль деревьев для регрессии.  
- **Градиентный бустинг для регрессии (GBTRegressor):** ансамбль деревьев с бустингом.  

#### Пример кода: Линейная регрессия

```python
from pyspark.ml.regression import LinearRegression

lr = LinearRegression(featuresCol="features", labelCol="label")
model = lr.fit(training_data)
predictions = model.transform(test_data)
```

                  
### Кластеризация
**Кластеризация** — поиск групп (кластеров) похожих объектов в неразмеченных данных.  
  
- **K-средних (KMeans):** алгоритм разделения данных на K кластеров по расстоянию до центроидов.  
- **Gaussian Mixture Model (GMM):** вероятностный подход к кластеризации на основе смеси гауссовых распределений.  
- **Bisecting K-means:** иерархический вариант алгоритма K-средних.  

#### Пример кода: KMeans

```python
from pyspark.ml.clustering import KMeans

kmeans = KMeans(featuresCol="features", k=3)
model = kmeans.fit(dataset)
predictions = model.transform(dataset)
```
                  
### Снижение размерности
- **Principal Component Analysis (PCA):** линейное преобразование для проекции данных в пространство меньшей размерности.  
- **Feature Selection:** методы отбора наиболее информативных признаков (ChiSqSelector, VectorSlicer).  

#### Пример кода: PCA

```python
from pyspark.ml.feature import PCA

pca = PCA(k=2, inputCol="features", outputCol="pcaFeatures")
model = pca.fit(dataset)
result = model.transform(dataset)
```