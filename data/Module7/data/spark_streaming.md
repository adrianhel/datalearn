## 7.10.1 Spark Streaming: потоковая обработка

### [Назад в Модуль 7 ⤶](/data/Module7/readme.md)

**Поток данных (Data Stream)** — непрерывная последовательность событий или сообщений, поступающих от источников 
данных в реальном времени, таких как сенсоры, логи серверов, сообщения в социальных сетях.  
  
**Мини-батч (Micro-batch)** — основной принцип работы Spark Streaming; поток данных разбивается на небольшие 
интервалы времени, в течение которых собранные данные обрабатываются как отдельный пакет (batch).  
  
**DStream (Discretized Stream)** — основной абстракцией потоковой обработки в Spark Streaming является 
дискретизированный поток. DStream представляет собой последовательность RDD, каждый из которых соответствует данным, 
собранным за определённый интервал времени.  
  
**RDD (Resilient Distributed Dataset)** — устойчивая распределённая коллекция данных, базовый элемент вычислений в Spark, 
обладающий свойствами отказоустойчивости и параллельности.  
  
**Источник данных (Input Source)** — внешний поток, из которого Spark Streaming получает данные. Примеры: Apache Kafka, 
Apache Flume, TCP-сокеты, HDFS, файловые системы.  
  
**Выходной поток (Output Sink)** — место назначения обработанных данных, например, файловая система, база данных, 
внешний сервис.  