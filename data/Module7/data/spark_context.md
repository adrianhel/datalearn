## 7.4 Spark Session и Spark Context

### [Назад в Модуль 7 ⤶](/data/Module7/readme.md)

В **Apache Spark** создание **Spark Session** является более предпочтительным подходом по сравнению с использованием 
**Spark Context**, т.к. Spark Context был основной входной точкой для программирования на Spark в более ранних версиях 
фреймворка. Он предоставлял основные функции и возможности Spark, такие, как создание **RDD** (Resilient Distributed Dataset) 
и выполнение операций над ними. Однако, с появлением **Spark 2.0** и выше, введение Spark Session стало рекомендованным 
способом работы с Spark.  

### Преимущества Spark Session по сравнению с Spark Context
1. **Удобство использования**: Spark Session предоставляет более удобный и единый интерфейс для работы с различными 
модулями Spark. Он упрощает кодирование и повышает производительность разработки.
2. **Поддержка различных типов данных**: Spark Session поддерживает работу с **RDD**, **DataFrames** и **Datasets**, что 
обеспечивает более гибкую обработку и анализ данных в Spark.
3. **Интеграция со сторонними инструментами**: Spark Session обеспечивает интеграцию с различными инструментами и 
библиотеками, такими как **Hive, **JDBC**, **Parquet**, **Avro** и другими.
4. **Улучшенная оптимизация**: Spark Session имеет лучшую оптимизацию выполнения запросов, что приводит к улучшенной 
производительности.
5. **Поддержка различных источников данных**: Spark Session позволяет работать с различными источниками данных, 
включая файловые системы (**HDFS**, **S3** и т.д.), базы данных (**MySQL**, **PostgreSQL** и др.), **Apache Kafka** и другие.  