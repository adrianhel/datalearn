## 7.8.1 Apache Parquet

### [Назад в Модуль 7 ⤶](/data/Module7/readme.md)

**Apache Parquet** – основной и самый рекомендуемый формат для большинства случаев использования в Spark. 
По умолчанию используется в многих дистрибутивах и версиях Spark.  

#### Преимущества
- Высокая производительность для запросов с агрегацией и фильтрацией по столбцам.  
- Поддержка сложных схем данных (вложенные структуры, массивы, карты).  
- Надежность, широкое распространение и отличная экосистема.  
- Поддержка предикатного pushdown (фильтры "проталкиваются" на уровень чтения данных).  

#### Недостатки
- Не предназначен для частых операций UPDATE/DELETE (хотя это возможно с помощью формата **Delta Lake**).  

```python
# Запись
df.write.parquet("/path/to/data.parquet")

# Чтение
df = spark.read.parquet("/path/to/data.parquet")
```
