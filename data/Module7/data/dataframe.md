## 7.6.1 Ð¡Ñ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð° Ð´Ð°Ð½Ð½Ñ‹Ñ… Dataframe

### [ÐÐ°Ð·Ð°Ð´ Ð² ÐœÐ¾Ð´ÑƒÐ»ÑŒ 7 â¤¶](/data/Module7/readme.md)

>**DataFrame** â€“ ÑÑ‚Ð¾ Ð°Ð±ÑÑ‚Ñ€Ð°ÐºÑ†Ð¸Ñ, Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð»ÑÑŽÑ‰Ð°Ñ ÑÐ¾Ð±Ð¾Ð¹ Ñ€Ð°ÑÐ¿Ñ€ÐµÐ´ÐµÐ»Ñ‘Ð½Ð½ÑƒÑŽ ÐºÐ¾Ð»Ð»ÐµÐºÑ†Ð¸ÑŽ Ð´Ð°Ð½Ð½Ñ‹Ñ…, Ð¾Ñ€Ð³Ð°Ð½Ð¸Ð·Ð¾Ð²Ð°Ð½Ð½Ñ‹Ñ… Ð² Ð²Ð¸Ð´Ðµ 
> Ð¸Ð¼ÐµÐ½Ð¾Ð²Ð°Ð½Ð½Ñ‹Ñ… ÑÑ‚Ð¾Ð»Ð±Ñ†Ð¾Ð², Ð°Ð½Ð°Ð»Ð¾Ð³Ð¸Ñ‡Ð½Ð¾ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ðµ Ð² Ñ€ÐµÐ»ÑÑ†Ð¸Ð¾Ð½Ð½Ð¾Ð¹ Ð±Ð°Ð·Ðµ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð¸Ð»Ð¸ Ð´Ð°Ñ‚Ð°Ñ„Ñ€ÐµÐ¹Ð¼Ñƒ Ð² Ñ‚Ð°ÐºÐ¸Ñ… ÑÐ·Ñ‹ÐºÐ°Ñ…, ÐºÐ°Ðº Python (Pandas) Ð¸ R.  

DataFrame Ð¾Ð±ÐµÑÐ¿ÐµÑ‡Ð¸Ð²Ð°ÐµÑ‚ Ð²Ñ‹ÑÐ¾ÐºÐ¾ÑƒÑ€Ð¾Ð²Ð½ÐµÐ²Ñ‹Ð¹ API Ð´Ð»Ñ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹ Ñ Ð±Ð¾Ð»ÑŒÑˆÐ¸Ð¼Ð¸ Ð¾Ð±ÑŠÑ‘Ð¼Ð°Ð¼Ð¸ Ð´Ð°Ð½Ð½Ñ‹Ñ…, Ñ€ÐµÐ°Ð»Ð¸Ð·ÑƒÑ ÑÑ„Ñ„ÐµÐºÑ‚Ð¸Ð²Ð½Ñ‹Ðµ Ð¼ÐµÑ…Ð°Ð½Ð¸Ð·Ð¼Ñ‹ 
Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ñ, Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ Ð¸ Ð°Ð½Ð°Ð»Ð¸Ð·Ð° ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ñ… Ð¸ Ð¿Ð¾Ð»Ñƒ-ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ….  

### ÐžÑÐ½Ð¾Ð²Ð½Ñ‹Ðµ Ð¿Ð¾Ð½ÑÑ‚Ð¸Ñ
- **Ð¡Ñ‚Ð¾Ð»Ð±ÐµÑ† (Column)** â€” Ð¸Ð¼ÐµÐ½Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹ Ð½Ð°Ð±Ð¾Ñ€ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð¾Ð´Ð½Ð¾Ð³Ð¾ Ñ‚Ð¸Ð¿Ð°, Ð°Ð½Ð°Ð»Ð¾Ð³Ð¸Ñ‡Ð½Ñ‹Ð¹ ÑÑ‚Ð¾Ð»Ð±Ñ†Ñƒ Ð² Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ðµ Ð±Ð°Ð·Ñ‹ Ð´Ð°Ð½Ð½Ñ‹Ñ….  
- **Ð¡Ñ‚Ñ€Ð¾ÐºÐ° (Row)** â€” Ð½Ð°Ð±Ð¾Ñ€ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ð¹, ÑÐ¾Ð¾Ñ‚Ð²ÐµÑ‚ÑÑ‚Ð²ÑƒÑŽÑ‰Ð¸Ñ… Ð¾Ð´Ð½Ð¾Ð¼Ñƒ ÑÐ»ÐµÐ¼ÐµÐ½Ñ‚Ñƒ Ð´Ð°Ð½Ð½Ñ‹Ñ…, Ð°Ð½Ð°Ð»Ð¾Ð³Ð¸Ñ‡Ð½Ñ‹Ð¹ ÑÑ‚Ñ€Ð¾ÐºÐµ Ð² Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ðµ Ð±Ð°Ð·Ñ‹ Ð´Ð°Ð½Ð½Ñ‹Ñ….  
- **Ð¡Ñ…ÐµÐ¼Ð° (Schema)** â€” ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð°, Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»ÑÑŽÑ‰Ð°Ñ Ð¸Ð¼ÐµÐ½Ð° ÑÑ‚Ð¾Ð»Ð±Ñ†Ð¾Ð² Ð¸ Ð¸Ñ… Ñ‚Ð¸Ð¿Ñ‹ Ð´Ð°Ð½Ð½Ñ‹Ñ….  
- **Ð”Ð¸ÑÑ‚Ñ€Ð¸Ð±ÑƒÑ†Ð¸Ñ (Distribution)** â€” Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð² DataFrame Ñ€Ð°ÑÐ¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ñ‹ Ð¿Ð¾ Ð¼Ð½Ð¾Ð¶ÐµÑÑ‚Ð²Ñƒ ÑƒÐ·Ð»Ð¾Ð² ÐºÐ»Ð°ÑÑ‚ÐµÑ€Ð° Ð´Ð»Ñ Ð¿Ð°Ñ€Ð°Ð»Ð»ÐµÐ»ÑŒÐ½Ð¾Ð¹ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸.  

**DataFrame** Ð¼Ð¾Ð¶Ð½Ð¾ Ñ€Ð°ÑÑÐ¼Ð°Ñ‚Ñ€Ð¸Ð²Ð°Ñ‚ÑŒ ÐºÐ°Ðº Ð´Ð²ÑƒÐ¼ÐµÑ€Ð½ÑƒÑŽ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñƒ, Ð³Ð´Ðµ ÐºÐ°Ð¶Ð´Ð°Ñ Ð·Ð°Ð¿Ð¸ÑÑŒ (ÑÑ‚Ñ€Ð¾ÐºÐ°) ÑÐ¾ÑÑ‚Ð¾Ð¸Ñ‚ Ð¸Ð· Ð½Ð°Ð±Ð¾Ñ€Ð° Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ð¹, 
Ð°ÑÑÐ¾Ñ†Ð¸Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ñ… Ñ Ð¸Ð¼ÐµÐ½Ð°Ð¼Ð¸ ÑÑ‚Ð¾Ð»Ð±Ñ†Ð¾Ð². Ð”Ð»Ñ ÐºÐ°Ð¶Ð´Ð¾Ð³Ð¾ ÑÑ‚Ð¾Ð»Ð±Ñ†Ð° Ð·Ð°Ð´Ð°Ð½ Ñ‚Ð¸Ð¿ Ð´Ð°Ð½Ð½Ñ‹Ñ…, Ñ‡Ñ‚Ð¾ Ð¿Ð¾Ð·Ð²Ð¾Ð»ÑÐµÑ‚ Ð¿Ñ€Ð¸Ð¼ÐµÐ½ÑÑ‚ÑŒ Ðº Ð´Ð°Ð½Ð½Ñ‹Ð¼ 
Ñ‚Ð¸Ð¿Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ðµ Ð¾Ð¿ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð¸ Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸Ð¸.  

```txt
+----------+-------+--------+
| name     | age   | salary |
+----------+-------+--------+
| "Ð˜Ð²Ð°Ð½"   | 30    | 50000  |
| "ÐœÐ°Ñ€Ð¸Ñ"  | 25    | 60000  |
| "ÐŸÐµÑ‚Ñ€"   | 29    | 70000  |
+----------+-------+--------+
```

## 7.6.2 Ð¢Ð¸Ð¿Ñ‹ Ð´Ð°Ð½Ð½Ñ‹Ñ…
Ð§Ð¸ÑÐ»Ð¾Ð²Ñ‹Ðµ: `IntegerType`, `LongType`, `FloatType`, `DoubleType`  
Ð¡Ñ‚Ñ€Ð¾ÐºÐ¾Ð²Ñ‹Ðµ: `StringType`  
Ð‘ÑƒÐ»ÐµÐ²Ñ‹: `BooleanType`  
Ð”Ð°Ñ‚Ð° Ð¸ Ð²Ñ€ÐµÐ¼Ñ: `DateType`, `TimestampType`  
Ð¡Ð»Ð¾Ð¶Ð½Ñ‹Ðµ Ñ‚Ð¸Ð¿Ñ‹: `ArrayType`, `MapType`, `StructType`  

## 7.6.3 Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ DataFrame
**DataFrame** Ð¼Ð¾Ð¶ÐµÑ‚ Ð±Ñ‹Ñ‚ÑŒ ÑÐ¾Ð·Ð´Ð°Ð½ Ð¸Ð· Ñ€Ð°Ð·Ð»Ð¸Ñ‡Ð½Ñ‹Ñ… Ð¸ÑÑ‚Ð¾Ñ‡Ð½Ð¸ÐºÐ¾Ð² Ð´Ð°Ð½Ð½Ñ‹Ñ…, Ð²ÐºÐ»ÑŽÑ‡Ð°Ñ:  
- Ð’Ð½ÐµÑˆÐ½Ð¸Ðµ Ñ„Ð°Ð¹Ð»Ñ‹ (CSV, Parquet, JSON, Avro Ð¸ Ð´Ñ€.)  
- Ð¢Ð°Ð±Ð»Ð¸Ñ†Ñ‹ Ð² Ñ€ÐµÐ»ÑÑ†Ð¸Ð¾Ð½Ð½Ñ‹Ñ… Ð±Ð°Ð·Ð°Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ… (Ñ‡ÐµÑ€ÐµÐ· JDBC)  
- RDD (Resilient Distributed Dataset)  
- Ð›Ð¾ÐºÐ°Ð»ÑŒÐ½Ñ‹Ðµ ÐºÐ¾Ð»Ð»ÐµÐºÑ†Ð¸Ð¸  

#### ÐŸÑ€Ð¸Ð¼ÐµÑ€ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ñ DataFrame Ð¸Ð· RDD

```python
from pyspark.sql import SparkSession, Row

spark = SparkSession.builder.getOrCreate()
rdd = spark.sparkContext.parallelize([
    Row(name="Ð˜Ð²Ð°Ð½", age=30, salary=50000),
    Row(name="ÐœÐ°Ñ€Ð¸Ñ", age=25, salary=60000)
])
df = spark.createDataFrame(rdd)
df.show()
```
                  
#### ÐŸÑ€Ð¸Ð¼ÐµÑ€ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ñ DataFrame Ð¸Ð· Ñ„Ð°Ð¹Ð»Ð° CSV

```python
df = spark.read.csv("employees.csv", header=True, inferSchema=True)
df.printSchema()
df.show()
```
                  
## 7.6.4 ÐœÐ°Ð½Ð¸Ð¿ÑƒÐ»ÑÑ†Ð¸Ð¸ Ð¸ Ð¾Ð¿ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð½Ð°Ð´ DataFrame
- Ð’Ñ‹Ð±Ð¾Ñ€ ÑÑ‚Ð¾Ð»Ð±Ñ†Ð¾Ð² (select): `df.select("name", "salary")`
- Ð¤Ð¸Ð»ÑŒÑ‚Ñ€Ð°Ñ†Ð¸Ñ ÑÑ‚Ñ€Ð¾Ðº (filter Ð¸Ð»Ð¸ where): `df.filter(df.age > 25)`
- ÐÐ³Ñ€ÐµÐ³Ð°Ñ†Ð¸Ñ (Ð³Ñ€ÑƒÐ¿Ð¿Ð¸Ñ€Ð¾Ð²ÐºÐ°): `df.groupBy("department").avg("salary")`
- Ð¡Ð¾Ñ€Ñ‚Ð¸Ñ€Ð¾Ð²ÐºÐ°: `df.orderBy(df.salary.desc())`
- Ð”Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ Ð½Ð¾Ð²Ñ‹Ñ… ÑÑ‚Ð¾Ð»Ð±Ñ†Ð¾Ð²: `df.withColumn("age_plus_ten", df.age + 10)`
- ÐžÐ±ÑŠÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ðµ DataFrame (join): `df1.join(df2, df1.id == df2.id)`
- Ð£Ð´Ð°Ð»ÐµÐ½Ð¸Ðµ Ð´ÑƒÐ±Ð»Ð¸ÐºÐ°Ñ‚Ð¾Ð²: `df.dropDuplicates()`
- Ð£Ð´Ð°Ð»ÐµÐ½Ð¸Ðµ ÑÑ‚Ð¾Ð»Ð±Ñ†Ð¾Ð²: `df.drop("salary")`

> ðŸ’¡ ÐžÐ¿ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð½Ð°Ð´ **DataFrame** Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»ÑÑŽÑ‚ Ð»Ð¾Ð³Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ Ð¿Ð»Ð°Ð½ Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ñ, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ð¹ Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð¸Ñ€ÑƒÐµÑ‚ÑÑ Ð¸ Ð¸ÑÐ¿Ð¾Ð»Ð½ÑÐµÑ‚ÑÑ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ 
> Ð¿Ñ€Ð¸ Ð½ÐµÐ¾Ð±Ñ…Ð¾Ð´Ð¸Ð¼Ð¾ÑÑ‚Ð¸ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ (Ð½Ð°Ð¿Ñ€Ð¸Ð¼ÐµÑ€, Ð¿Ñ€Ð¸ Ð²Ñ‹Ð·Ð¾Ð²Ðµ Ð¼ÐµÑ‚Ð¾Ð´Ð¾Ð² `show()`, `collect()`, `count()`). Ð¢Ð°ÐºÐ¾Ð¹ Ð¿Ð¾Ð´Ñ…Ð¾Ð´ 
> Ð¿Ð¾Ð·Ð²Ð¾Ð»ÑÐµÑ‚ Ð¼Ð¸Ð½Ð¸Ð¼Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð¸Ð·Ð±Ñ‹Ñ‚Ð¾Ñ‡Ð½Ñ‹Ðµ Ð²Ñ‹Ñ‡Ð¸ÑÐ»ÐµÐ½Ð¸Ñ Ð¸ Ð¿Ð¾Ð²Ñ‹ÑÐ¸Ñ‚ÑŒ Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ.  

## 7.6.5 Ð¡Ñ…ÐµÐ¼Ð° Ð¸ Ñ‚Ð¸Ð¿Ð¸Ð·Ð°Ñ†Ð¸Ñ
Ð¡Ñ…ÐµÐ¼Ð° DataFrame Ð¼Ð¾Ð¶ÐµÑ‚ Ð±Ñ‹Ñ‚ÑŒ ÐºÐ°Ðº ÑÐ²Ð½Ð¾ Ð·Ð°Ð´Ð°Ð½Ð° Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÐµÐ¼, Ñ‚Ð°Ðº Ð¸ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸ Ð²Ñ‹Ð²ÐµÐ´ÐµÐ½Ð° Ð¿Ñ€Ð¸ Ñ‡Ñ‚ÐµÐ½Ð¸Ð¸ Ð´Ð°Ð½Ð½Ñ‹Ñ….  
Ð¯Ð²Ð½Ð°Ñ Ñ‚Ð¸Ð¿Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð¾Ð±ÐµÑÐ¿ÐµÑ‡Ð¸Ð²Ð°ÐµÑ‚ ÑÑ‚Ñ€Ð¾Ð³Ð¸Ð¹ ÐºÐ¾Ð½Ñ‚Ñ€Ð¾Ð»ÑŒ Ñ‚Ð¸Ð¿Ð¾Ð², Ð¿Ñ€ÐµÐ´Ð¾Ñ‚Ð²Ñ€Ð°Ñ‰Ð°Ñ Ð¾ÑˆÐ¸Ð±ÐºÐ¸ Ð½Ð° ÑÑ‚Ð°Ð¿Ðµ Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ñ.  

```python
from pyspark.sql.types import StructType, StructField, StringType, IntegerType

schema = StructType([
    StructField("name", StringType(), True),
    StructField("age", IntegerType(), True),
    StructField("salary", IntegerType(), True)
])

df = spark.read.csv("employees.csv", header=True, schema=schema)
df.printSchema()
```

## 7.6.6 SQL-Ð¿Ð¾Ð´Ð¾Ð±Ð½Ñ‹Ðµ Ð¾Ð¿ÐµÑ€Ð°Ñ†Ð¸Ð¸
DataFrame Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶Ð¸Ð²Ð°ÐµÑ‚ Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ðµ SQL-Ð·Ð°Ð¿Ñ€Ð¾ÑÐ¾Ð². Ð”Ð»Ñ ÑÑ‚Ð¾Ð³Ð¾ DataFrame Ñ€ÐµÐ³Ð¸ÑÑ‚Ñ€Ð¸Ñ€ÑƒÐµÑ‚ÑÑ ÐºÐ°Ðº Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ð°Ñ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ð°, Ð¿Ð¾ÑÐ»Ðµ Ñ‡ÐµÐ³Ð¾ 
Ðº Ð½ÐµÐ¹ Ð¼Ð¾Ð³ÑƒÑ‚ Ð±Ñ‹Ñ‚ÑŒ Ð¿Ñ€Ð¸Ð¼ÐµÐ½ÐµÐ½Ñ‹ SQL-Ð¾Ð¿ÐµÑ€Ð°Ñ‚Ð¾Ñ€Ñ‹.  

```python
df.createOrReplaceTempView("employees")
result = spark.sql("SELECT name, salary FROM employees WHERE age > 25")
result.show()
```

## 7.6.7 ÐŸÑ€Ð¸Ð¼ÐµÑ€Ñ‹ Ð¿Ñ€Ð°ÐºÑ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ð³Ð¾ Ð¿Ñ€Ð¸Ð¼ÐµÐ½ÐµÐ½Ð¸Ñ DataFrame
ÐÐ½Ð°Ð»Ð¸Ñ‚Ð¸ÐºÐ° Ð±Ð¾Ð»ÑŒÑˆÐ¸Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð¸ Ð¿Ð¾ÑÑ‚Ñ€Ð¾ÐµÐ½Ð¸Ðµ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚Ð¾Ð² Ð¿Ð¾ ÐºÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ð¼ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ°Ð¼ Ð±Ð¸Ð·Ð½ÐµÑÐ°  
ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð¸ Ð¾Ñ‡Ð¸ÑÑ‚ÐºÐ° Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð´Ð»Ñ Ð¿Ð¾ÑÐ»ÐµÐ´ÑƒÑŽÑ‰ÐµÐ³Ð¾ Ð¼Ð°ÑˆÐ¸Ð½Ð½Ð¾Ð³Ð¾ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ  
Ð˜Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ†Ð¸Ñ Ð¸ Ð¾Ð±ÑŠÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ðµ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð¸Ð· Ñ€Ð°Ð·Ð»Ð¸Ñ‡Ð½Ñ‹Ñ… Ð¸ÑÑ‚Ð¾Ñ‡Ð½Ð¸ÐºÐ¾Ð²  
ÐŸÐ¾Ð´Ð³Ð¾Ñ‚Ð¾Ð²ÐºÐ° Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð´Ð»Ñ Ð²Ð¸Ð·ÑƒÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ð¸ Ð¸ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°  
Ð ÐµÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ ÑÐ»Ð¾Ð¶Ð½Ñ‹Ñ… ETL-Ð¿Ñ€Ð¾Ñ†ÐµÑÑÐ¾Ð² (Extract, Transform, Load)  

## 7.6.8 ÐŸÑ€ÐµÐ¸Ð¼ÑƒÑ‰ÐµÑÑ‚Ð²Ð° DataFrame
- Ð’Ñ‹ÑÐ¾ÐºÐ¾ÑƒÑ€Ð¾Ð²Ð½ÐµÐ²Ñ‹Ð¹ API Ñ Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶ÐºÐ¾Ð¹ ÑˆÐ¸Ñ€Ð¾ÐºÐ¾Ð³Ð¾ Ð½Ð°Ð±Ð¾Ñ€Ð° Ð¾Ð¿ÐµÑ€Ð°Ñ†Ð¸Ð¹  
- ÐžÐ¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ñ Ñ‡ÐµÑ€ÐµÐ· ÐºÐ°Ñ‚Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ¾Ð² Ð¸ Ñ„Ð¸Ð·Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ Ð¿Ð»Ð°Ð½Ð¸Ñ€Ð¾Ð²Ñ‰Ð¸Ðº  
- ÐÐ²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ðµ ÑƒÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ Ñ€Ð°ÑÐ¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸ÐµÐ¼ Ð¸ Ð¿Ð°Ñ€Ñ‚Ð¸Ñ†Ð¸Ð¾Ð½Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸ÐµÐ¼ Ð´Ð°Ð½Ð½Ñ‹Ñ…  
- Ð˜Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ†Ð¸Ñ Ñ Ñ€Ð°Ð·Ð»Ð¸Ñ‡Ð½Ñ‹Ð¼Ð¸ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ð°Ð¼Ð¸ Ð¸ Ð¸ÑÑ‚Ð¾Ñ‡Ð½Ð¸ÐºÐ°Ð¼Ð¸ Ð´Ð°Ð½Ð½Ñ‹Ñ…  
- ÐŸÐ¾Ð´Ð´ÐµÑ€Ð¶ÐºÐ° Ð¼Ð½Ð¾Ð³Ð¾ÑÐ·Ñ‹Ñ‡Ð½Ñ‹Ñ… Ð¸Ð½Ñ‚ÐµÑ€Ñ„ÐµÐ¹ÑÐ¾Ð² (Python, Scala, Java, R)  

## 7.6.9 ÐžÐ³Ñ€Ð°Ð½Ð¸Ñ‡ÐµÐ½Ð¸Ñ DataFrame
- ÐžÐ³Ñ€Ð°Ð½Ð¸Ñ‡ÐµÐ½Ð½Ð°Ñ Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶ÐºÐ° Ð½Ð¸Ð·ÐºÐ¾ÑƒÑ€Ð¾Ð²Ð½ÐµÐ²Ñ‹Ñ… Ð¾Ð¿ÐµÑ€Ð°Ñ†Ð¸Ð¹ Ð¿Ð¾ ÑÑ€Ð°Ð²Ð½ÐµÐ½Ð¸ÑŽ Ñ RDD  
- Ð¡Ð»Ð¾Ð¶Ð½Ð¾ÑÑ‚Ð¸ Ð¿Ñ€Ð¸ Ñ€Ð°Ð±Ð¾Ñ‚Ðµ Ñ Ð½ÐµÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¼Ð¸ Ð¸Ð»Ð¸ ÑÐ¸Ð»ÑŒÐ½Ð¾ Ð²Ð»Ð¾Ð¶ÐµÐ½Ð½Ñ‹Ð¼Ð¸ Ð´Ð°Ð½Ð½Ñ‹Ð¼Ð¸  
- Ð—Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚ÑŒ Ð¾Ñ‚ ÐºÐ¾Ñ€Ñ€ÐµÐºÑ‚Ð½Ð¾Ð³Ð¾ Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ñ ÑÑ…ÐµÐ¼Ñ‹ Ð´Ð°Ð½Ð½Ñ‹Ñ…  

## 7.6.10 Ð¤Ð¾Ñ€Ð¼ÑƒÐ»Ñ‹ Ð¸ Ð²Ñ‹Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ
ÐœÐ½Ð¾Ð³Ð¸Ðµ Ð¾Ð¿ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ñ€ÐµÐ°Ð»Ð¸Ð·ÑƒÑŽÑ‚ÑÑ Ñ Ð¿Ð¾Ð¼Ð¾Ñ‰ÑŒÑŽ Ð²Ñ‹Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹, Ð½Ð°Ð¿Ñ€Ð¸Ð¼ÐµÑ€:
- ÐÐ³Ñ€ÐµÐ³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ: `df.groupBy("department").sum("salary")`
- Ð’Ñ‹Ñ‡Ð¸ÑÐ»ÐµÐ½Ð¸Ðµ Ð½Ð¾Ð²Ñ‹Ñ… ÑÑ‚Ð¾Ð»Ð±Ñ†Ð¾Ð²: `df.withColumn("bonus", df.salary * 0.1)`
- Ð¤Ð¸Ð»ÑŒÑ‚Ñ€Ð°Ñ†Ð¸Ñ Ð¿Ð¾ ÑƒÑÐ»Ð¾Ð²Ð¸ÑŽ: `df.filter(df.salary > 50000)`

## 7.6.11 