# 7. Apache Spark

### [Назад в Содержание ⤶](/README.md)

## 7.1 Знакомство с Apache Spark
> ***Apache Spark*** — это _open-source_ распределённая вычислительная платформа, предназначенная для обработки 
> больших объемов данных.

**Spark** — это молниеносный унифицированный аналитический движок, используемый для кластерных вычислений с большими 
массивами данных (_BigData, Hadoop_) с целью параллельного выполнения программ на нескольких узлах.

### Эко система Apache Spark

<img src="/data/Module7/img/spark_system.png" width="50%">

**Spark** представляет собой комбинацию нескольких библиотек: _SQL, Dataframes, GraphX, MLlib_ и _Spark Streaming_.

> **Apache Spark** разработан на языке программирования **Scala** и работает на **JVM**.

## 7.2 Установка Apache Spark

[Руководство по установке и настройке Apache Spark (локально)](data/spark_install.md)  

[Руководство по установке и настройке Apache Spark (docker-compose)](data/spark_dc_install.md)

## 7.3 Режимы работы Apache Spark
**Spark** работает в 4 различных режимах:
- **Автономный режим**: все процессы выполняются в рамках одного процесса *JVM*.  
- **Автономный кластерный режим**: используется встроенная в **Spark** система планирования заданий.  
- **Apache Mesos**: рабочие узлы работают на разных компьютерах, но драйвер работает только на главном узле.  
- **Hadoop YARN**: драйверы работают на главном узле приложения и управляются *YARN* в кластере.  

